# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wS4TNeGbpDE0BcnyF61Ma9E6r2lj28PJ
"""

import streamlit as st
import numpy as np
import pandas as pd
import joblib
import tensorflow as tf
from tensorflow.keras.models import load_model

# --- Configuration (Based on your training steps) ---
# Sequence Length jo aapne Step 7 mein use ki thi
SEQ_LEN = 500
MODEL_PATH = "ecg_model_final.h5"  # Ensure this file name matches the one you uploaded to GitHub
ENCODER_PATH = "label_encoder.joblib" # Ensure this file name matches the one you uploaded to GitHub

# --- Data Pre-processing Function (From your Step 7 logic) ---
def pad_truncate(sig, length=SEQ_LEN):
    """Pads or truncates a 1D signal to a fixed length (500)."""
    sig = np.asarray(sig, dtype=float)
    if len(sig) >= length:
        # Truncate
        return sig[:length]
    else:
        # Pad with zeros (important: padding ensures consistent input size)
        pad = np.zeros(length - len(sig))
        return np.concatenate([sig, pad])

# --- Model Loading (Using Streamlit caching for efficiency) ---
@st.cache_resource
def load_assets():
    """Loads the model and LabelEncoder once."""
    try:
        # 1. Load Model
        model = load_model(MODEL_PATH)
        # 2. Load Label Encoder
        le = joblib.load(ENCODER_PATH)

        # 3. Get Class Names
        # Check if le has been fit properly
        if hasattr(le, 'classes_'):
            class_names = le.classes_.tolist()
        else:
            st.error("Label Encoder is corrupted or not properly saved.")
            return None, None, None

        st.sidebar.success(f"Model and Encoder loaded successfully.")
        return model, le, class_names

    except FileNotFoundError as e:
        st.error(f"FATAL ERROR: Required file not found: {e}. Ensure all files are committed to GitHub.")
        return None, None, None
    except Exception as e:
        st.error(f"FATAL ERROR during model loading: {e}. Check TensorFlow/h5py version compatibility.")
        return None, None, None

# Load the assets
model, le, CLASS_NAMES = load_assets()

# --- Streamlit App UI and Logic ---

st.title("â¤ï¸ ECG Heart Disease Classification (1D CNN)")
st.markdown("---")

# ðŸ›‘ SAFEGUARD: Agar loading fail hui to yahan app ruk jayegi
if model is None or le is None or CLASS_NAMES is None:
    # Error message already shown in load_assets()
    st.stop()

# Agar sab kuch theek hai, toh info dikhayein
st.caption(f"Model configured for {SEQ_LEN} time steps and {len(CLASS_NAMES)} classes: {', '.join(CLASS_NAMES)}")


uploaded_file = st.file_uploader("Upload ECG CSV File", type=["csv"], help="The CSV should contain raw ECG signal values (one row per signal).")

if uploaded_file is not None:
    try:
        # 1. Load Data
        data = pd.read_csv(uploaded_file, header=None)

        # Determine signals list (Assuming each row is a signal of varying length)
        signals_list = []
        for index in range(data.shape[0]):
            # Use to_numeric to safely extract signal data
            row_data = pd.to_numeric(data.iloc[index].values, errors='coerce')
            signals_list.append(row_data[~np.isnan(row_data)])

        if not signals_list or all(len(sig) == 0 for sig in signals_list):
            st.error("Could not parse the ECG signal from the CSV. Ensure it contains numeric values.")
            st.stop()

        # 2. Pre-process Signals (Pad/Truncate and Reshape)
        processed_signals = [pad_truncate(sig) for sig in signals_list]
        X_predict = np.stack(processed_signals)
        # Reshape for Conv1D: (samples, SEQ_LEN, 1)
        X_predict = X_predict[..., np.newaxis]

        st.subheader("ðŸ“Š Signal Preview (First Signal)")
        st.line_chart(X_predict[0].flatten())
        st.info(f"Processed {len(signals_list)} signals, each standardized to length {SEQ_LEN}.")

        # 3. Prediction
        st.subheader("ðŸ¤– Prediction Result")
        predict_button = st.button("Run Classification")

        if predict_button:
            with st.spinner("Classifying ECG signals..."):
                pred_probas = model.predict(X_predict, verbose=0)

                # Handle Binary vs Multi-class (based on model output shape)
                if model.output_shape[-1] == 1: # Binary classification
                    predicted_classes_indices = (pred_probas.flatten() >= 0.5).astype(int)
                else: # Multi-class classification (5 classes in your case)
                    predicted_classes_indices = np.argmax(pred_probas, axis=1)

                # Convert index to actual class name
                predicted_class_names = le.inverse_transform(predicted_classes_indices)

                # 4. Display Results (for the first signal only)
                st.markdown("---")
                st.markdown(f"**Result for the first uploaded signal:**")

                # Get max probability for confidence
                max_proba = np.max(pred_probas[0])

                st.success(f"**Predicted Class:** **{predicted_class_names[0]}**")
                st.write(f"Confidence: **{max_proba:.2f}**")

                # Show all class probabilities in a detailed table
                st.markdown("##### Detailed Probabilities:")
                proba_df = pd.DataFrame({
                    "Class": CLASS_NAMES,
                    "Probability": pred_probas[0]
                }).sort_values(by="Probability", ascending=False).reset_index(drop=True)

                st.dataframe(proba_df, use_container_width=True, hide_index=True)


    except Exception as e:
        st.error(f"An unexpected error occurred during file processing or prediction: {e}")