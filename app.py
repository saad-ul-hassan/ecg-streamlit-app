# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wS4TNeGbpDE0BcnyF61Ma9E6r2lj28PJ
"""

import streamlit as st
import numpy as np
import pandas as pd
import joblib
import tensorflow as tf
from tensorflow.keras.models import load_model

# --- Configuration (Based on your training steps) ---
SEQ_LEN = 500
MODEL_PATH = "ecg_model_final.h5"  # Model file name
ENCODER_PATH = "label_encoder.joblib" # Label Encoder file name

# --- Data Pre-processing Function (From your Step 7 logic) ---
def pad_truncate(sig, length=SEQ_LEN):
    """Pads or truncates a 1D signal to a fixed length (500)."""
    sig = np.asarray(sig, dtype=float)
    if len(sig) >= length:
        # Truncate
        return sig[:length]
    else:
        # Pad with zeros
        pad = np.zeros(length - len(sig))
        return np.concatenate([sig, pad])

# --- Model Loading (Using Streamlit caching for efficiency) ---
@st.cache_resource
def load_assets():
    """Loads the model and LabelEncoder once."""
    try:
        model = load_model(MODEL_PATH)
        le = joblib.load(ENCODER_PATH)
        # Class names derived from the loaded LabelEncoder
        class_names = le.classes_.tolist()
        return model, le, class_names
    except Exception as e:
        st.error(f"Error loading model or encoder. Check if {MODEL_PATH} and {ENCODER_PATH} are in the same directory: {e}")
        return None, None, None

model, le, CLASS_NAMES = load_assets()

# --- Streamlit App UI and Logic ---

st.title("â¤ï¸ ECG Heart Disease Classification (1D CNN)")
st.caption(f"Model configured for {SEQ_LEN} time steps and {len(CLASS_NAMES)} classes: {', '.join(CLASS_NAMES)}")
st.markdown("---")

if model is None:
    st.stop()

uploaded_file = st.file_uploader("Upload ECG CSV File", type=["csv"], help="The CSV should contain raw ECG signal values (one row per signal).")

if uploaded_file is not None:
    try:
        # 1. Load Data
        data = pd.read_csv(uploaded_file, header=None)

        # Determine signals list (Assuming each row is a signal)
        signals_list = []
        for index in range(data.shape[0]):
            # Try to get data from row, ignoring non-numeric columns if any
            row_data = pd.to_numeric(data.iloc[index].values, errors='coerce')
            signals_list.append(row_data[~np.isnan(row_data)])

        if not signals_list or all(len(sig) == 0 for sig in signals_list):
            st.error("Could not parse the ECG signal from the CSV. Ensure it contains numeric values.")
            st.stop()

        # 2. Pre-process Signals (Pad/Truncate and Reshape)
        processed_signals = [pad_truncate(sig) for sig in signals_list]
        X_predict = np.stack(processed_signals)
        # Reshape for Conv1D: (samples, SEQ_LEN, 1)
        X_predict = X_predict[..., np.newaxis]

        st.subheader("ðŸ“Š Signal Preview (First Signal)")
        st.line_chart(X_predict[0].flatten())
        st.info(f"Processed {len(signals_list)} signals, each standardized to length {SEQ_LEN}.")

        # 3. Prediction
        st.subheader("ðŸ¤– Prediction Result")
        predict_button = st.button("Run Prediction")

        if predict_button:
            with st.spinner("Classifying ECG signals..."):
                pred_probas = model.predict(X_predict, verbose=0)

                # Handle Binary vs Multi-class
                if model.output_shape[-1] == 1: # Binary classification (Sigmoid)
                    predicted_classes_indices = (pred_probas.flatten() >= 0.5).astype(int)
                else: # Multi-class classification (Softmax - 5 classes in your case)
                    predicted_classes_indices = np.argmax(pred_probas, axis=1)

                predicted_class_names = le.inverse_transform(predicted_classes_indices)

                # 4. Display Results (for the first signal)
                st.markdown("---")
                st.markdown(f"**Result for the first uploaded signal:**")

                # Get max probability for confidence
                max_proba = np.max(pred_probas[0])

                st.success(f"**Predicted Class:** **{predicted_class_names[0]}**")
                st.write(f"Confidence: **{max_proba:.2f}**")

                # Show all class probabilities
                st.markdown("##### Detailed Probabilities:")
                proba_df = pd.DataFrame({
                    "Class": CLASS_NAMES,
                    "Probability": pred_probas[0]
                }).sort_values(by="Probability", ascending=False).reset_index(drop=True)

                st.dataframe(proba_df, use_container_width=True, hide_index=True)


    except Exception as e:
        st.error(f"An error occurred during processing the file: {e}")